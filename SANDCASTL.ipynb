{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **üèñÔ∏è SANDCASTL üèñÔ∏è**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **‚ú® Input Requirements ‚ú®**\n",
    "### ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full Directory Path for Input Spectrum (WAVELENGTH, FLUX, NOISE)\n",
    "input_file = \n",
    "\n",
    "# Input outfile file name (DO NOT PUT DIRECTORY OR FILETYPE)\n",
    "output_file = \n",
    "\n",
    "# Input the estimated spectral type (M0 = 0, L0 = 10, T0 = 20, NO GREATER THAN 30)\n",
    "spt_estimate = \n",
    "\n",
    "# Set the number of threads used\n",
    "thread = \n",
    "\n",
    "# Set the number of walkers\n",
    "walkers = \n",
    "\n",
    "# Set the number of steps\n",
    "steps = \n",
    "\n",
    "# Set the number of discards\n",
    "discard = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports All Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports all required packages \n",
    "import io\n",
    "import os\n",
    "import csv\n",
    "import splat\n",
    "import emcee\n",
    "import corner\n",
    "import contextlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import splat.model as spmdl\n",
    "from astropy import units as u\n",
    "import matplotlib.pyplot as plt\n",
    "from specutils import Spectrum1D\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpolation Between Grid Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolates between grid points so that the MCMC simulation can fit a more accurate model\n",
    "def interpolation(mcmc_parm, real_parm, observed_wave, wavemove):\n",
    "    \n",
    "    # Gets the lower and upper bounds in the grid space\n",
    "    lower_temp, upper_temp = real_parm[0], real_parm[1]\n",
    "    lower_logg, upper_logg = real_parm[2], real_parm[3]\n",
    "    lower_metal, upper_metal = real_parm[4], real_parm[5]\n",
    "\n",
    "    # Gets the desired location to interpolate to\n",
    "    x, y, z = mcmc_parm[0], mcmc_parm[1], mcmc_parm[2]\n",
    "\n",
    "    # Makes a list of all of the required spectra on the grid\n",
    "    model_list = [(spmdl.getModel(teff = lower_temp, logg = lower_logg, z = lower_metal, co = 0.55, cld = 'o0.55', logkzz = 2, set = 'lowz')),\n",
    "                  (spmdl.getModel(teff = upper_temp, logg = lower_logg, z = lower_metal, co = 0.55, cld = 'o0.55', logkzz = 2, set = 'lowz')),\n",
    "                  (spmdl.getModel(teff = lower_temp, logg = upper_logg, z = lower_metal, co = 0.55, cld = 'o0.55', logkzz = 2, set = 'lowz')),\n",
    "                  (spmdl.getModel(teff = upper_temp, logg = upper_logg, z = lower_metal, co = 0.55, cld = 'o0.55', logkzz = 2, set = 'lowz')),\n",
    "                  (spmdl.getModel(teff = lower_temp, logg = lower_logg, z = upper_metal, co = 0.55, cld = 'o0.55', logkzz = 2, set = 'lowz')),\n",
    "                  (spmdl.getModel(teff = upper_temp, logg = lower_logg, z = upper_metal, co = 0.55, cld = 'o0.55', logkzz = 2, set = 'lowz')),\n",
    "                  (spmdl.getModel(teff = lower_temp, logg = upper_logg, z = upper_metal, co = 0.55, cld = 'o0.55', logkzz = 2, set = 'lowz')),\n",
    "                  (spmdl.getModel(teff = upper_temp, logg = upper_logg, z = upper_metal, co = 0.55, cld = 'o0.55', logkzz = 2, set = 'lowz'))]\n",
    "\n",
    "    # Resamples the wavelength regions of the model to be the same as the observed spectrum\n",
    "    for i in range(len(model_list)): \n",
    "        model_wave = model_list[i].wave\n",
    "        model_flux = model_list[i].flux\n",
    "        input_spec = Spectrum1D(spectral_axis=model_wave, flux=model_flux) \n",
    "        f = interp1d(model_wave, model_flux, kind='linear')\n",
    "        resampled_fluxes = f(observed_wave)\n",
    "        model_list[i] = np.log10(resampled_fluxes)\n",
    "        \n",
    "    # Performs the interpolation\n",
    "    f_intern = interpolate.griddata(([lower_temp, upper_temp, lower_temp, upper_temp, lower_temp, upper_temp, lower_temp, upper_temp], \n",
    "                                   [lower_logg, lower_logg, upper_logg, upper_logg, lower_logg, lower_logg, upper_logg, upper_logg], \n",
    "                                   [lower_metal, lower_metal, lower_metal, lower_metal, upper_metal, upper_metal, upper_metal, upper_metal]), \n",
    "                                   model_list, (x, y, z), method = 'linear', rescale = True)\n",
    "    \n",
    "    # Returns the interpolated fluxes in correct units\n",
    "    f_intern = [x**10 for x in f_intern]\n",
    "    return f_intern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\chi^2$ Statistical Test Function\n",
    "#### Formula: $\\chi^2 = \\frac{1}{N-P}\\sum_{i = 1}^{N} \\frac{(O_{i} - E_{i})^2}{\\sigma_{i}^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounds to the nearest hundred\n",
    "def closest_hundreds(value):\n",
    "    lower_hundred = (value // 100) * 100\n",
    "    upper_hundred = lower_hundred + 100\n",
    "    return lower_hundred, upper_hundred\n",
    "\n",
    "# Rounds to the nearest half\n",
    "def closest_bounds(target, numbers):\n",
    "    lower_bound = max(num for num in numbers if num <= target)\n",
    "    upper_bound = min(num for num in numbers if num >= target)\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Rounds to either -0.5 or -1.5\n",
    "def round_to_negative_half_or_one_half(number):\n",
    "    rounded_value = round(number) - 0.5 if number - int(number) < 0.5 else round(number) - 1.5\n",
    "    return rounded_value\n",
    "\n",
    "# Defines the chi^2 statistical approach for our MCMC simulation\n",
    "def chi_square(observed_wave, observed_flux, observed_noise, parm): \n",
    "    \n",
    "    # Loads in the model spectrum\n",
    "    target_numbers = [4, 4.5, 5, 5.25]\n",
    "    target_metal = [-2, -1.5, -1, -0.5, -0.25, 0]\n",
    "    grid_parm = [closest_hundreds(parm[0])[0], closest_hundreds(parm[0])[1], \n",
    "                 closest_bounds(parm[1], target_numbers)[0], closest_bounds(parm[1], target_numbers)[1],\n",
    "                 closest_bounds(parm[2], target_metal)[0], closest_bounds(parm[2], target_metal)[1]]\n",
    "    model_flux = interpolation(parm, grid_parm, observed_wave, parm[4])\n",
    "\n",
    "    # Fixes the spectra with null values so it can be normalized and normalizes it\n",
    "    model_flux = np.nan_to_num(model_flux, nan=2.2250738585072014e-30)\n",
    "    percentile_995 = np.nanpercentile(model_flux, 99.5)\n",
    "    model_flux = np.array(model_flux) / percentile_995\n",
    "    model_flux = [x + parm[3] for x in model_flux]\n",
    "    model_flux = gaussian_filter1d(model_flux, 1.4)\n",
    "    \n",
    "    # Performs the chi square calculations and returns it\n",
    "    chi_square = np.nansum(((observed_flux - model_flux) / observed_noise) ** 2)\n",
    "    N, P = len(observed_flux), 5\n",
    "    reduced_chi_square = chi_square / (N - P)\n",
    "    return reduced_chi_square\n",
    "\n",
    "# Loads in the observed spectrum into SPLAT\n",
    "observed = splat.Spectrum(input_file)\n",
    "\n",
    "# Gets the observed wavelength\n",
    "observed_wave = observed.wave.value\n",
    "observed_wave = observed_wave[int(len(observed_wave)*0.05): len(observed_wave) - int(len(observed_wave)*0.05)]\n",
    "\n",
    "# Gets the observed noise for the fluxes\n",
    "observed_noise = [x for x in observed.noise.value]\n",
    "observed_noise = observed_noise[int(len(observed_noise)*0.05): len(observed_noise) - int(len(observed_noise)*0.05)]\n",
    "\n",
    "# Gets the observed fluxes\n",
    "observed_flux = [x for x in observed.flux.value]\n",
    "observed_flux = observed_flux[int(len(observed_flux)*0.05): len(observed_flux) - int(len(observed_flux)*0.05)]\n",
    "\n",
    "# Normalizes the observed noise and fluxes\n",
    "observed_noise = [(x / np.nanmax(observed.flux.value)) for x in observed_noise]\n",
    "observed_flux = [x / np.percentile(observed_flux, 99.1) for x in observed_flux]\n",
    "observed_flux = [x if x >= 0 else 2.2250738585072014e-30 for x in observed_flux]\n",
    "observed_flux = np.nan_to_num(observed_flux, nan=2.2250738585072014e-30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Makes the Parameter Space and Verifies the Walkers are Going in the Correct Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimates temperature based off spectral type estimate\n",
    "teff_estimate = 2200 - 100*(spt_estimate - 10)\n",
    "lower_teff = teff_estimate - 500\n",
    "if lower_teff < 500: \n",
    "    lower_teff = 500\n",
    "upper_teff = teff_estimate + 500\n",
    "if upper_teff > 5000: \n",
    "    upper_teff = 5000\n",
    "\n",
    "# Defines the parameter space    \n",
    "def prior(parm):\n",
    "    a, b, c, d, e = parm\n",
    "    if lower_teff < a < upper_teff and 4 < b < 6 and -1.5 < c < -0.5 and -0.2 < d < 0.2 and -0.001 < e < 0.001:\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "# Verifies that the walkers are going in the correct direction\n",
    "def posterior(parm):\n",
    "    prior_val = prior(parm)\n",
    "    if not np.isfinite(prior_val):\n",
    "        return -np.inf\n",
    "    return prior_val - 0.5 * chi_square(observed_wave, observed_flux, observed_noise, parm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up the MCMC Code Using the EMCEE Package (MAY TAKE A COUPLE OF MINUTES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the number of parameters, walkers, threads, and steps for the MCMC simulation\n",
    "ndim, nwalkers = 5, walkers\n",
    "threads, n_steps = thread, steps\n",
    "\n",
    "# Makes the random innitial position of the walkers and the MCMC simulation\n",
    "initial_positions = np.random.uniform(low=[teff_estimate - 100, 5, -1, -0.05, -0.001], high=[teff_estimate + 100, 6, -0.5, 0.05, 0.001], size=(nwalkers, ndim))\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, posterior, threads = thread)\n",
    " \n",
    "# Runs the MCMC simulation #\n",
    "# ------------------------------------------------------------ #\n",
    "with contextlib.redirect_stdout(io.StringIO()):\n",
    "    sampler.run_mcmc(initial_positions, n_steps, progress=True)\n",
    "# ------------------------------------------------------------ #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finds the Best Values and the Errors From the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses EMCEE's discard tool, finds the best parameters, and finds the uncertainties from the simulation\n",
    "flat_samples = sampler.get_chain(discard=discard, thin=15, flat=True)\n",
    "best_fit_params = []\n",
    "for i in range(ndim):\n",
    "    mcmc = np.percentile(flat_samples[:, i], [5, 50, 95])\n",
    "    best_fit_params.append([mcmc[0], mcmc[1], mcmc[2]])\n",
    "\n",
    "# Prints these values\n",
    "fraction_string = f\"{'cm'}\\u2044{'s^2'}\"\n",
    "chi2_final = chi_square(observed_wave, observed_flux, observed_noise, [best_fit_params[0][1], best_fit_params[1][1], best_fit_params[2][1], best_fit_params[3][1], best_fit_params[4][1]])\n",
    "print('#--------------------------------------------------------------------------#')\n",
    "print('                     Best Fit Parameters \\u03C72 = ' + str(round((np.median(chi2_final)), 3)))\n",
    "print('#--------------------------------------------------------------------------#')\n",
    "print(\"  Best Fit Parameters: Teff = \" + str(round(best_fit_params[0][1], 1)) + 'K, log(g) = ' + str(round(best_fit_params[1][1], 3)) + str(fraction_string) + ', [M/H] = ' + str(round(best_fit_params[2][1], 3)))\n",
    "print('#--------------------------------------------------------------------------#')\n",
    "print(\"    Lower Estimate: Teff = \" + str(round(best_fit_params[0][0], 1)) + 'K, log(g) = ' + str(round(best_fit_params[1][0], 3)) + str(fraction_string) + ', [M/H] = ' + str(round(best_fit_params[2][0], 3)))\n",
    "print(\"    Upper Estimate: Teff = \" + str(round(best_fit_params[0][2], 1)) + 'K, log(g) = ' + str(round(best_fit_params[1][2], 3)) + str(fraction_string) + ', [M/H] = ' + str(round(best_fit_params[2][2], 3)))\n",
    "print('#--------------------------------------------------------------------------#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots the Comparison of the Spectrum, Walker Space, and a Corner Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main figure and subplots\n",
    "fig1, axs = plt.subplots(6, 1, figsize=(10, 15), gridspec_kw={'height_ratios': [4, 1, 1, 1, 1, 1]})\n",
    "\n",
    "# Plots out the parameter chain for the walkers\n",
    "# -------------------------------------------------------------- #\n",
    "# Creates a flattened sample and the labels\n",
    "samples = sampler.get_chain()\n",
    "labels = [\"$T_{eff}$\", \"log(g)\", \"[M/H]\", '‚àÜF', '‚àÜŒª']\n",
    "\n",
    "# Plots the data for every parameter\n",
    "for i in range(ndim):\n",
    "    # Makes the axis look pretty\n",
    "    axs[i + 1].plot(samples[:, :, i], \"k\", alpha=0.4)\n",
    "    axs[i + 1].set_xlim(0, len(samples))\n",
    "    axs[i + 1].set_ylabel(labels[i], fontsize = 25, fontname='Times New Roman')\n",
    "    axs[i + 1].minorticks_on()\n",
    "    axs[i + 1].grid(True, alpha = 0.5)\n",
    "    axs[i + 1].tick_params(which='minor', width=1, length=3, labelsize=10)\n",
    "    axs[i + 1].tick_params(which='major', width = 2, length = 6, labelsize = 10)\n",
    "    axs[i + 1].tick_params(axis='x', labelsize=9)\n",
    "    axs[i + 1].tick_params(axis='y', labelsize=9, labelrotation=45)\n",
    "\n",
    "# Makes the general plot look pretty\n",
    "axs[5].set_xlabel('Step Number', fontsize = 25, fontname='Times New Roman')\n",
    "\n",
    "# Saves how the walkers explore into a .csv file\n",
    "split_arrays = np.split(samples, 5, axis=2)\n",
    "for i, arr in enumerate(split_arrays):\n",
    "    flattened_array = arr.reshape((steps, walkers))\n",
    "    columns = [f'WALKER_{j+1}' for j in range(walkers)]\n",
    "    df = pd.DataFrame(flattened_array, columns=columns)\n",
    "    if i == 0: name = 'teff'\n",
    "    if i == 1: name = 'logg'\n",
    "    if i == 2: name = 'MH'\n",
    "    if i == 3: name = 'delta_flux'\n",
    "    if i == 4: name = 'delta_micron'\n",
    "    df.to_csv('Output/' + str(output_file) + 'parameter_' + str(name) + '.csv', index=False)\n",
    "# -------------------------------------------------------------- #\n",
    "\n",
    "# Plots out the comparison of the observed and model spectra\n",
    "# -------------------------------------------------------------- #\n",
    "# Gets the observed data\n",
    "observed = splat.Spectrum(input_file)\n",
    "observed.normalize()\n",
    "observed_wave, observed_flux, observed_noise = observed.wave.value, [x for x in observed.flux.value], [x for x in observed.noise.value]\n",
    "\n",
    "# Trims the observed data\n",
    "observed_wave = observed_wave[int(len(observed_wave)*0.05): len(observed_wave) - int(len(observed_wave)*0.05)]\n",
    "observed_flux = observed_flux[int(len(observed_flux)*0.05): len(observed_flux) - int(len(observed_flux)*0.05)]\n",
    "observed_noise = observed_noise[int(len(observed_noise)*0.05): len(observed_noise) - int(len(observed_noise)*0.05)]\n",
    "\n",
    "# Normalize the observed spectrum\n",
    "observed_noise = [(x / np.nanmax(observed.flux.value)) for x in observed_noise]\n",
    "observed_flux =  [((x / np.nanpercentile(observed_flux, 99.1))) for x in observed_flux]\n",
    "observed_flux =  [x if x >= 0 else 2.2250738585072014e-30 for x in observed_flux]\n",
    "\n",
    "# Gets the best fitted model line fluxes\n",
    "grid_parm = [closest_hundreds(best_fit_params[0][1])[0], closest_hundreds(best_fit_params[0][1])[1], closest_halves(best_fit_params[1][1])[0], closest_halves(best_fit_params[1][1])[1]]\n",
    "model_flux = interpolation([best_fit_params[0][1], best_fit_params[1][1], best_fit_params[2][1]], grid_parm, observed_wave, best_fit_params[4][1]) \n",
    "model_flux = [(((x) / np.nanpercentile(model_flux, 99.5))) for x in model_flux]\n",
    "\n",
    "# Plots the data\n",
    "axs[0].plot(observed_wave, observed_flux, lw=2, c='k', label='Observed')\n",
    "axs[0].plot(observed_wave, observed_noise, lw=2, c='gray', label='Noise', alpha = 0.3)\n",
    "model_flux = [x + best_fit_params[3][1] for x in model_flux]\n",
    "model_flux = gaussian_filter1d(model_flux, 1.4)\n",
    "if (len(model_flux) - len(observed_wave)) == 0:\n",
    "    axs[0].plot(observed_wave, model_flux, lw=2, c='lime', label='Best Fit Model')\n",
    "else: \n",
    "    try: \n",
    "        axs[0].plot(observed_wave[0:len(model_flux)], model_flux, lw=2, c='lime', label='Best Fit Model')\n",
    "    except: \n",
    "        axs[0].plot(observed_wave, model_flux[0:len(observed_wave)], lw=2, c='lime', label='Best Fit Model')\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df = pd.DataFrame({'WAVELENGTH': observed_wave, 'FLUX': model_flux})\n",
    "df.to_csv(output_file + '_fitted-spectra.csv', index=False)\n",
    "        \n",
    "# Makes the axis look pretty\n",
    "axs[0].set_xlabel(' WAVELENGTH ($\\mu$m)', fontsize = 25, fontname='Times New Roman'), axs[0].set_ylabel('Flux', fontsize = 25, fontname='Times New Roman')\n",
    "axs[0].minorticks_on()\n",
    "axs[0].grid(True, alpha = 0.5)\n",
    "axs[0].tick_params(which='minor', width=1, length=3, labelsize=10)\n",
    "axs[0].tick_params(which='major', width = 2, length = 6, labelsize = 10)\n",
    "axs[0].tick_params(axis='x', labelsize=12)\n",
    "axs[0].tick_params(axis='y', labelsize=12, labelrotation=45)\n",
    "\n",
    "# Adds a title and legend\n",
    "legend = axs[0].legend(prop={'family': 'Times New Roman', 'size': 20})\n",
    "axs[0].set_ylim(-0.1, 1.1)\n",
    "legend.set_frame_on(False)\n",
    "\n",
    "# Saves the figure\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure1.jpeg')\n",
    "plt.close('all')\n",
    "# -------------------------------------------------------------- #\n",
    "\n",
    "# Plots out the corner plots\n",
    "# -------------------------------------------------------------- #\n",
    "# Gets the upper and lower errors\n",
    "upper_error_t, lower_error_t = round(best_fit_params[0][2] - best_fit_params[0][1], 1), round(best_fit_params[0][1] - best_fit_params[0][0], 1)\n",
    "upper_error_g, lower_error_g = round(best_fit_params[1][2] - best_fit_params[1][1], 2), round(best_fit_params[1][1] - best_fit_params[1][0], 2)\n",
    "upper_error_m, lower_error_m = round(best_fit_params[2][2] - best_fit_params[2][1], 2), round(best_fit_params[2][1] - best_fit_params[2][0], 2)\n",
    "upper_error_f, lower_error_f = round(best_fit_params[3][2] - best_fit_params[3][1], 3), round(best_fit_params[3][1] - best_fit_params[3][0], 3)\n",
    "upper_error_w, lower_error_w = round(best_fit_params[4][2] - best_fit_params[4][1], 3), round(best_fit_params[4][1] - best_fit_params[4][0], 3)\n",
    "\n",
    "# Makes the limits for the corner plot\n",
    "limits = [(best_fit_params[0][0] - (lower_error_t/2), best_fit_params[0][2] + (upper_error_t/2)), \n",
    "          (best_fit_params[1][0] - (lower_error_g/2), best_fit_params[1][2] + (upper_error_g/2)), \n",
    "          (best_fit_params[2][0] - (lower_error_m/2), best_fit_params[2][2] + (upper_error_m/2)), \n",
    "          (best_fit_params[3][0] - (lower_error_f/2), best_fit_params[3][2] + (upper_error_f/2)), \n",
    "          (best_fit_params[4][0] - (lower_error_w/2), best_fit_params[4][2] + (upper_error_w/2))]\n",
    "\n",
    "# Plots the corner plot\n",
    "figure = corner.corner(flat_samples, labels=labels, truths=[best_fit_params[0][1], best_fit_params[1][1], best_fit_params[2][1], best_fit_params[3][1], best_fit_params[4][1]], \n",
    "                       truth_color='lime', title_fmt='.2f', title_kwargs={'fontsize': 25}, plot_contours=True, label_kwargs={'fontsize': 25}, quantiles=[0.05, 0.5, 0.95], use_math_text=True, range=limits)\n",
    "\n",
    "# Sets the titles for the corner plots\n",
    "titles = [fr'$Teff = {round(best_fit_params[0][1], 1)}^{{+{upper_error_t}}}_{{-{lower_error_t}}}$' + 'K',\n",
    "          fr'$log(g) = {round(best_fit_params[1][1], 2)}^{{+{upper_error_g}}}_{{-{lower_error_g}}}$', \n",
    "           fr'$[M/H] = -{abs(round(best_fit_params[2][1], 2))}^{{+{upper_error_m}}}_{{-{lower_error_m}}}$', \n",
    "           fr'$‚àÜF = {(round(best_fit_params[3][1], 3))}^{{+{upper_error_f}}}_{{-{lower_error_f}}}$', \n",
    "           fr'$‚àÜŒª = {(round(best_fit_params[4][1], 4))}^{{+{upper_error_w}}}_{{-{lower_error_w}}}$']\n",
    "list = [0, 6, 12, 18, 24]\n",
    "for i in range(len(list)):\n",
    "    ax = figure.axes[list[i]]\n",
    "    ax.set_title(titles[i], fontsize=20)\n",
    "    \n",
    "# Saves the figure\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(15, 15) \n",
    "plt.savefig('figure2.jpeg')\n",
    "plt.close('all')\n",
    "\n",
    "# Flattens the sample and saves it\n",
    "flat_samples = sampler.get_chain(discard=discard, thin=15, flat=True)\n",
    "df = pd.DataFrame({'FLAT_SAMPLE': flat_samples.tolist()})\n",
    "df.to_csv('Ouput/' + output_file + '_flat-sample.csv', index=False)\n",
    "# -------------------------------------------------------------- #\n",
    "\n",
    "# Combines the 2 pdfs\n",
    "# -------------------------------------------------------------- #\n",
    "# Makes function to combine to pdfs side-by-side\n",
    "def merge_images_side_by_side(image1_path, image2_path, output_path):\n",
    "    \n",
    "    # Open the two images\n",
    "    image1 = Image.open(image1_path)\n",
    "    image2 = Image.open(image2_path)\n",
    "\n",
    "    # Get the sizes of the images\n",
    "    width1, height1 = image1.size\n",
    "    width2, height2 = image2.size\n",
    "    total_width = width1 + width2\n",
    "    max_height = max(height1, height2)\n",
    "\n",
    "    # Creates the new merged image\n",
    "    merged_image = Image.new(\"RGB\", (total_width, max_height))\n",
    "    merged_image.paste(image1, (0, 0))\n",
    "    merged_image.paste(image2, (width1, 0))\n",
    "    merged_image.save(output_path)\n",
    "\n",
    "# Puts down the image names\n",
    "image1_path = 'figure1.jpeg'\n",
    "image2_path = 'figure2.jpeg'\n",
    "output_path = 'Ouput/' + output_file + '.png'\n",
    "\n",
    "# Merges the 2 images and removes the temp. state\n",
    "merge_images_side_by_side(image1_path, image2_path, output_path)\n",
    "os.remove( 'figure1.jpeg')\n",
    "os.remove('figure2.jpeg')\n",
    "# -------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **üé¨ END OF SANDCASTL üé¨**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
